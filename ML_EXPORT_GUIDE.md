# üìä ML Data Export Guide

–≠—Ç–æ—Ç –≥–∞–π–¥ –ø–æ–∫–∞–∂–µ—Ç –∫–∞–∫ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å ML –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–æ—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç Apache Parquet –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.

## üéØ –ß—Ç–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è?

–°–∫—Ä–∏–ø—Ç —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç **3 —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö**:

### 1. **signals** (–≤–æ—à–µ–¥—à–∏–µ —Å–¥–µ–ª–∫–∏)
- –í—Å–µ —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –±–æ—Ç –≤–æ—à–µ–ª –≤ –ø–æ–∑–∏—Ü–∏—é
- –°–æ–¥–µ—Ä–∂–∏—Ç: —Ü–µ–Ω—ã –≤—Ö–æ–¥–∞/SL/TP, –∏—Å—Ö–æ–¥—ã (PnL, MFE, MAE), ML –∫–æ–Ω—Ç–µ–∫—Å—Ç (–¥–∏—Å—Ç–∞–Ω—Ü–∏–∏ –¥–æ –∑–æ–Ω, arrival pattern)
- –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: "–ß—Ç–æ –¥–µ–ª–∞–µ—Ç —Å–∏–≥–Ω–∞–ª –ø—Ä–∏–±—ã–ª—å–Ω—ã–º?"

### 2. **near_miss_skips** (–ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã)
- –ö–∞–Ω–¥–∏–¥–∞—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –±–æ—Ç –ù–ï –≤–∑—è–ª (skip reasons)
- –°–æ–¥–µ—Ä–∂–∏—Ç: –ø–æ–ª–Ω—ã–π ML –∫–æ–Ω—Ç–µ–∫—Å—Ç, –ø—Ä–∏—á–∏–Ω—ã –æ—Ç–∫–∞–∑–∞, –º–∞–∫—Ä–æ–∫–æ–Ω—Ç–µ–∫—Å—Ç (BTC —Ç—Ä–µ–Ω–¥, –∑–æ–Ω—ã)
- –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: "–ö–∞–∫–∏–µ –ø—Ä–æ–ø—É—Å–∫–∏ –±—ã–ª–∏ –æ—à–∏–±–æ—á–Ω—ã–º–∏?"

### 3. **shadow_evaluations** (–≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å—Ö–æ–¥—ã –ø—Ä–æ–ø—É—Å–∫–æ–≤)
- –ß—Ç–æ –±—ã —Å–ª—É—á–∏–ª–æ—Å—å, –µ—Å–ª–∏ –±—ã –º—ã –≤–æ—à–ª–∏ –≤ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª
- –°–æ–¥–µ—Ä–∂–∏—Ç: –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ MFE/MAE, –∏—Å—Ö–æ–¥—ã (TP/SL)
- –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: "–ù–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–∏ –Ω–∞—à–∏ skip rules?"

---

## üöÄ –ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å —ç–∫—Å–ø–æ—Ä—Ç

### –ù–∞ VPS:

```bash
cd /root/CandleSearchBot

# –≠–∫—Å–ø–æ—Ä—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 30 –¥–Ω–µ–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
tsx src/scripts/exportParquet.ts

# –≠–∫—Å–ø–æ—Ä—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 7 –¥–Ω–µ–π
tsx src/scripts/exportParquet.ts --days=7

# –≠–∫—Å–ø–æ—Ä—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 90 –¥–Ω–µ–π –≤ –∫–∞—Å—Ç–æ–º–Ω—É—é –ø–∞–ø–∫—É
tsx src/scripts/exportParquet.ts --days=90 --output=./exports_90d
```

### –í—ã–≤–æ–¥ —Å–∫—Ä–∏–ø—Ç–∞:

```
üöÄ Starting ML data export to Parquet format
üìÖ Exporting last 30 days of data
üìÇ Output directory: ./ml_exports

üìä Exporting SIGNALS (entered trades)...
‚úÖ Exported 142 signals to ./ml_exports/signals_2025-10-29.parquet

üìä Exporting NEAR_MISS_SKIPS (skipped signals)...
‚úÖ Exported 1847 near-miss skips to ./ml_exports/near_miss_skips_2025-10-29.parquet

üìä Exporting SHADOW_EVALUATIONS...
‚úÖ Exported 89 shadow evaluations to ./ml_exports/shadow_evaluations_2025-10-29.parquet

============================================================
üéâ Export completed successfully!
============================================================
üìÇ Files saved to: /root/CandleSearchBot/ml_exports
```

---

## üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–º–ø—å—é—Ç–µ—Ä

### –í–∞—Ä–∏–∞–Ω—Ç 1: SCP (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```bash
# –°–∫–∞—á–∞—Ç—å –≤—Å—é –ø–∞–ø–∫—É —Å —ç–∫—Å–ø–æ—Ä—Ç–∞–º–∏
scp -r root@YOUR_VPS_IP:/root/CandleSearchBot/ml_exports ./ml_data

# –ò–ª–∏ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
scp root@YOUR_VPS_IP:/root/CandleSearchBot/ml_exports/signals_2025-10-29.parquet ./
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: –ó–∞–ø–∞–∫–æ–≤–∞—Ç—å –≤ –∞—Ä—Ö–∏–≤ (–¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤)

–ù–∞ VPS:
```bash
cd /root/CandleSearchBot
tar -czf ml_exports_$(date +%Y%m%d).tar.gz ml_exports/
```

–ù–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–∞—à–∏–Ω–µ:
```bash
scp root@YOUR_VPS_IP:/root/CandleSearchBot/ml_exports_*.tar.gz ./
tar -xzf ml_exports_*.tar.gz
```

---

## üêç –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –≤ Python

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:

```bash
pip install pandas pyarrow scikit-learn matplotlib seaborn
```

### –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö:

```python
import pandas as pd
import pyarrow.parquet as pq

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–æ—à–µ–¥—à–∏–µ —Å–¥–µ–ª–∫–∏
df_signals = pd.read_parquet('ml_exports/signals_2025-10-29.parquet')

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã
df_skips = pd.read_parquet('ml_exports/near_miss_skips_2025-10-29.parquet')

# –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ–Ω–µ–≤—ã–µ –æ—Ü–µ–Ω–∫–∏
df_shadow = pd.read_parquet('ml_exports/shadow_evaluations_2025-10-29.parquet')

print(f"üìä Loaded {len(df_signals)} signals, {len(df_skips)} skips, {len(df_shadow)} shadow evals")
```

### –ü—Ä–∏–º–µ—Ä—ã –∞–Ω–∞–ª–∏–∑–∞:

#### 1. Win Rate –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º:

```python
# –¢–æ–ª—å–∫–æ –∑–∞–∫—Ä—ã—Ç—ã–µ —Å–¥–µ–ª–∫–∏
closed = df_signals[df_signals['status'].isin(['TP1_HIT', 'TP2_HIT', 'TP3_HIT', 'SL_HIT'])]

# Win = –ª—é–±–æ–π TP
closed['is_win'] = closed['status'].str.contains('TP')

# Win rate –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
win_rate = closed.groupby('pattern_type')['is_win'].agg(['mean', 'count'])
print(win_rate)
```

#### 2. –ê–Ω–∞–ª–∏–∑ skip reasons:

```python
# –†–∞—Å–ø–∞—Ä—Å–∏—Ç—å –º–∞—Å—Å–∏–≤ skip_reasons (—Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ CSV string)
df_skips['reasons_list'] = df_skips['skip_reasons'].str.split(',')

# –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –∫–∞–∂–¥–æ–π –ø—Ä–∏—á–∏–Ω—ã
from collections import Counter
all_reasons = Counter([r for reasons in df_skips['reasons_list'] for r in reasons])
print(all_reasons.most_common(10))
```

#### 3. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å –∏—Å—Ö–æ–¥–∞–º–∏:

```python
# –¢–æ–ª—å–∫–æ TP2 –∏ SL —Å–¥–µ–ª–∫–∏
outcome_data = closed[closed['status'].isin(['TP2_HIT', 'SL_HIT'])].copy()
outcome_data['hit_tp'] = outcome_data['status'] == 'TP2_HIT'

# –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è ML —Ñ–∏—á —Å –∏—Å—Ö–æ–¥–æ–º
features = ['dist_to_dir_h1_zone_atr', 'dist_to_dir_h4_zone_atr', 'free_path_r']
correlations = outcome_data[features + ['hit_tp']].corr()['hit_tp'].drop('hit_tp')
print(correlations.sort_values(ascending=False))
```

#### 4. Shadow vs Real —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ:

```python
# –°–æ–µ–¥–∏–Ω–∏—Ç—å skip —Å shadow evaluation
merged = df_skips.merge(
    df_shadow[df_shadow['is_active'] == False],
    left_on='signal_id',
    right_on='signal_id'
)

# –°–∫–æ–ª—å–∫–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –≤—Å–µ —Ä–∞–≤–Ω–æ —Å—Ä–∞–±–æ—Ç–∞–ª–∏ –±—ã?
shadow_wins = merged[merged['shadow_outcome'].isin(['tp1', 'tp2'])]
print(f"üéØ {len(shadow_wins)} / {len(merged)} –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –≤—Å–µ —Ä–∞–≤–Ω–æ —Å—Ä–∞–±–æ—Ç–∞–ª–∏ –±—ã")
```

---

## üìà –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ ML –ø–∞–π–ø–ª–∞–π–Ω—ã

### 1. Binary Classification (TP vs SL)

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
X = closed[['dist_to_dir_h1_zone_atr', 'dist_to_dir_h4_zone_atr', 'free_path_r']]
y = closed['is_win']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# –û–±—É—á–µ–Ω–∏–µ
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Feature importance
importance = pd.DataFrame({
    'feature': X.columns,
    'importance': clf.feature_importances_
}).sort_values('importance', ascending=False)

print(importance)
```

### 2. Regression (PnL prediction)

```python
from sklearn.ensemble import GradientBoostingRegressor

# –¢–æ–ª—å–∫–æ TP —Å–¥–µ–ª–∫–∏
wins = closed[closed['is_win'] == True]

X = wins[['dist_to_dir_h1_zone_atr', 'free_path_r']]
y = wins['pnl_r']

reg = GradientBoostingRegressor(n_estimators=100, random_state=42)
reg.fit(X_train, y_train)
```

---

## üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —ç–∫—Å–ø–æ—Ä—Ç (cron)

–î–æ–±–∞–≤—å—Ç–µ –≤ crontab –Ω–∞ VPS:

```bash
# –≠–∫—Å–ø–æ—Ä—Ç –∫–∞–∂–¥—É—é –Ω–µ–¥–µ–ª—é –≤ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ –≤ 00:00
0 0 * * 0 cd /root/CandleSearchBot && tsx src/scripts/exportParquet.ts --days=7 >> /root/export_log.txt 2>&1
```

---

## üìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

### signals.parquet

| –ö–æ–ª–æ–Ω–∫–∞ | –¢–∏–ø | –û–ø–∏—Å–∞–Ω–∏–µ |
|---------|-----|----------|
| id | int | ID —Å–∏–≥–Ω–∞–ª–∞ |
| symbol | string | –¢–∏–∫–µ—Ä (BTCUSDT) |
| pattern_type | string | pinbar_buy, ppr_sell, etc |
| entry_price | float | –¶–µ–Ω–∞ –≤—Ö–æ–¥–∞ |
| pnl_r | float | PnL –≤ R (TP2=2R, SL=-1R) |
| dist_to_dir_h1_zone_atr | float | –î–∏—Å—Ç–∞–Ω—Ü–∏—è –¥–æ H1 –∑–æ–Ω—ã –≤ ATR |
| free_path_r | float | –°–≤–æ–±–æ–¥–Ω—ã–π –ø—É—Ç—å –≤ R |
| arrival_pattern | enum | impulse_up, compression, chop |
| first_touch | string | tp1/tp2/sl - —á—Ç–æ —Å—Ä–∞–±–æ—Ç–∞–ª–æ –ø–µ—Ä–≤—ã–º |

### near_miss_skips.parquet

| –ö–æ–ª–æ–Ω–∫–∞ | –¢–∏–ø | –û–ø–∏—Å–∞–Ω–∏–µ |
|---------|-----|----------|
| signal_id | uuid | –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ |
| symbol | string | –¢–∏–∫–µ—Ä |
| skip_reasons | string | CSV —Å–ø–∏—Å–æ–∫ –∫–æ–¥–æ–≤ (R01, R03, R07) |
| dist_to_dir_h4_zone_atr | float | –î–∏—Å—Ç–∞–Ω—Ü–∏—è –¥–æ H4 –∑–æ–Ω—ã |
| btc_trend_state | enum | up/down/neutral |
| zones | json | –ü–æ–ª–Ω—ã–π —Å–Ω–∞–ø—à–æ—Ç –∑–æ–Ω |

### shadow_evaluations.parquet

| –ö–æ–ª–æ–Ω–∫–∞ | –¢–∏–ø | –û–ø–∏—Å–∞–Ω–∏–µ |
|---------|-----|----------|
| signal_id | uuid | FK –∫ near_miss_skips |
| shadow_outcome | enum | tp1, tp2, sl, timeout |
| shadow_mfe_r | float | –ú–∞–∫—Å–∏–º—É–º –ø—Ä–∏–±—ã–ª–∏ –≤ R |
| shadow_mae_r | float | –ú–∞–∫—Å–∏–º—É–º —É–±—ã—Ç–∫–∞ –≤ R |

---

## ‚ùì FAQ

**Q: –ö–∞–∫ —á–∞—Å—Ç–æ –Ω—É–∂–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ?**  
A: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ä–∞–∑ –≤ –Ω–µ–¥–µ–ª—é. –î–ª—è –∂–∏–≤–æ–≥–æ ML - –µ–∂–µ–¥–Ω–µ–≤–Ω–æ.

**Q: –°–∫–æ–ª—å–∫–æ –º–µ—Å—Ç–∞ –∑–∞–Ω–∏–º–∞—é—Ç —Ñ–∞–π–ª—ã?**  
A: ~1-5 MB –Ω–∞ 1000 —Å–∏–≥–Ω–∞–ª–æ–≤ (Parquet –æ—á–µ–Ω—å –∫–æ–º–ø–∞–∫—Ç–µ–Ω!).

**Q: –ú–æ–∂–Ω–æ –ª–∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ?**  
A: –î–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `--days=1` –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—É—Ç–∫–∏.

**Q: –ö–∞–∫ –æ—Ç–∫—Ä—ã—Ç—å .parquet –±–µ–∑ Python?**  
A: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ DuckDB: `SELECT * FROM 'signals.parquet' LIMIT 10;`

---

üéâ **–ì–æ—Ç–æ–≤–æ!** –¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å ML –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –º–æ–¥–µ–ª–µ–π!
